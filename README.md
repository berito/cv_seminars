# cv_seminars

## Seminar 2

### References

##### ATTENTION MECHANISMS AND THEIR IMPACT ON COMPUTER VISION MODELS
1. [A. Dosovitskiy et al., "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale," ICLR, 2021.](https://arxiv.org/abs/2010.11929)
2. [H. Touvron et al., "Training data-efficient image transformers and distillation through attention," ICML, 2021.](https://arxiv.org/abs/2012.12877)
3. [N. Carion et al., "End-to-End Object Detection with Transformers," ECCV, 2020.](https://arxiv.org/abs/2005.12872)
4. [S. Zheng et al., "Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers," CVPR, 2021](https://arxiv.org/abs/2012.15840)
5. [Z. Huang et al., "CCNet: Criss-Cross Attention for Semantic Segmentation," ICCV, 2019](https://openaccess.thecvf.com/content_ICCV_2019/papers/Huang_CCNet_Criss-Cross_Attention_for_Semantic_Segmentation_ICCV_2019_paper.pdf)
6. [H. Li et al., "Pyramid Attention Network for Semantic Segmentation," AAAI, 2019](https://ojs.aaai.org/index.php/AAAI/article/view/4396)
7. [G. Bertasius and J. Wang, "Learning Temporal Attention in Dilated Convolutional Networks for Action Recognition," CVPR, 2022](https://openaccess.thecvf.com/content/CVPR2022/papers/Bertasius_Learning_Temporal_Attention_in_Dilated_Convolutional_Networks_for_Action_Recognition_CVPR_2022_paper.pdf)
8. [A. Rnab et al., "ViViT: A Video Vision Transformer," ICCV, 2021](https://openaccess.thecvf.com/content/ICCV2021/papers/Arnab_ViViT_A_Video_Vision_Transformer_ICCV_2021_paper.pdf)
9. [A. Vaswani et al., "Attention is All You Need," NeurIPS, 2017](https://arxiv.org/abs/1706.03762)



## Seminar 1